import streamlit as st
import requests
from bs4 import BeautifulSoup
from itertools import cycle
import traceback

# ==========================
# Proxy list (rotation)
# ==========================
proxies_list = [
    {"ip": "46.249.100.124", "port": "80", "type": "http"},
    {"ip": "5.161.133.32", "port": "80", "type": "http"},
    {"ip": "78.38.67.210", "port": "3636", "type": "socks4"},
]

proxy_cycle = cycle(proxies_list)


# ==========================
# Function to fetch URL
# ==========================
def fetch_url(url):
    """
    Fetch URL content by rotating through proxies until success.
    Handles decoding issues and proxy timeouts gracefully.
    """
    for proxy_data in proxy_cycle:
        proxy = {
            "http": f"{proxy_data['type']}://{proxy_data['ip']}:{proxy_data['port']}",
            "https": f"{proxy_data['type']}://{proxy_data['ip']}:{proxy_data['port']}",
        }

        try:
            st.write(f"üåê Testing proxy: {proxy_data['ip']}:{proxy_data['port']} ({proxy_data['type']})")

            response = requests.get(
                url,
                headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                                       "AppleWebKit/537.36 (KHTML, like Gecko) "
                                       "Chrome/120.0.0.0 Safari/537.36"},
                proxies=proxy,
                timeout=12,
            )

            # Only continue if success
            if response.status_code == 200:
                try:
                    # try normal decode
                    html = response.content.decode("utf-8", errors="ignore")
                except Exception:
                    # fallback to text
                    html = str(response.text)

                if "<html" in html.lower():
                    return html
                else:
                    st.warning("‚ö†Ô∏è Response isn't valid HTML ‚Äî skipping this proxy.")
            else:
                st.warning(f"‚ö†Ô∏è Status {response.status_code} from {proxy_data['ip']}")
        except Exception as e:
            st.warning(f"‚ùå Proxy {proxy_data['ip']} failed: {str(e)}")

    return None


# ==========================
# Streamlit UI
# ==========================
st.set_page_config(page_title="Multi-Proxy Fetcher", page_icon="üåç", layout="centered")

st.title("üåç Multi-Proxy URL Fetcher")
st.markdown("**Automatically test multiple proxies to fetch any webpage (even Iranian sites).**")

url = st.text_input("üîó Enter website URL:", "https://namnak.com/fall-rozane-30-mehr-1404.p111860")

if st.button("üöÄ Fetch HTML"):
    if not url.startswith("http"):
        url = "https://" + url

    with st.spinner("‚è≥ Fetching page using proxies..."):
        try:
            html = fetch_url(url)
        except Exception as e:
            st.error("Unexpected error:\n\n" + traceback.format_exc())
            html = None

    if html:
        try:
            soup = BeautifulSoup(html, "html.parser")
            st.success("‚úÖ Page fetched successfully!")
            st.text_area("üìÑ HTML Preview (first 5000 chars)", soup.prettify()[:5000], height=400)
        except Exception as e:
            st.error(f"Error parsing HTML: {e}")
    else:
        st.error("‚ùå Could not fetch the page using any proxy.")
